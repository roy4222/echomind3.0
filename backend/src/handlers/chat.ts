import { Env } from '../index';
import { corsHeaders, getCorsHeadersForRequest } from '../utils/cors';
import { verifyAuth } from '../middlewares/auth';
import type { ChatMessage, ChatCompletionOptions, GroqChatResponse } from './../types/chat';

/**
 * ç³»çµ±æç¤ºè©è¨­å®š
 * å®šç¾© AI åŠ©æ‰‹çš„è§’è‰²å’Œè¡Œç‚ºæº–å‰‡
 */
const SYSTEM_PROMPT: ChatMessage = {
  role: 'system',
  content: `ä½ æ˜¯è¼”ä»å¤§å­¸è³‡è¨Šç®¡ç†å­¸ç³»çš„ AI åŠ©æ‰‹ï¼Œåå« EchoMindã€‚
  - ä½¿ç”¨ç¹é«”ä¸­æ–‡å›ç­”
  - å›ç­”è¦ç°¡æ½”ä½†å°ˆæ¥­
  - å°å­¸ç”Ÿè¦å‹å–„æœ‰è€å¿ƒ
  - ä¸ç¢ºå®šçš„äº‹æƒ…è¦èª å¯¦èªªä¸çŸ¥é“
  - éœ€è¦æ™‚å¯ä»¥ä½¿ç”¨ Markdown æ ¼å¼ç¾åŒ–å›ç­”
  - å°ˆæ³¨æ–¼è³‡ç®¡ç›¸é—œçš„å­¸è¡“ã€èª²ç¨‹ã€å°±æ¥­è«®è©¢
  - é¿å…è¨è«–æ”¿æ²»ã€å®—æ•™ç­‰æ•æ„Ÿè©±é¡Œ`
};

/**
 * é è¨­é…ç½®åƒæ•¸
 */
const DEFAULT_MODEL = 'llama-3.1-8b-instant';  // é è¨­ä½¿ç”¨çš„èªè¨€æ¨¡å‹
const DEFAULT_TEMPERATURE = 0.7;                // é è¨­çš„æº«åº¦åƒæ•¸
const DEFAULT_MAX_TOKENS = 2048;               // é è¨­çš„æœ€å¤§ token æ•¸

/**
 * æ¨¡å‹åƒæ•¸æ˜ å°„è¡¨
 * æä¾›ä¸åŒæ¨¡å‹çš„é…ç½®åƒæ•¸å’Œé¡¯ç¤ºåç¨±
 */
const MODEL_MAPPING = {
  default: {
    name: 'llama-3.1-8b-instant',
    displayName: 'Llama 3.1 8B Instant',
    temperature: 0.7,
    maxTokens: 2048
  },
  advanced: {
    name: 'deepseek-r1-distill-llama-70b',
    displayName: 'Deepseek R1 Distill Llama 70B',
    temperature: 0.5,
    maxTokens: 4096
  },
  creative: {
    name: 'qwen-2.5-32b',
    displayName: 'Qwen 2.5 32B',
    temperature: 0.9,
    maxTokens: 3072
  },
  maverick: {
    name: 'meta-llama/llama-4-maverick-17b-128e-instruct',
    displayName: 'Llama 4 Maverick 17B',
    temperature: 0.7,
    maxTokens: 4096
  }
};

/**
 * è™•ç†èŠå¤©è«‹æ±‚
 * @param request è«‹æ±‚å°è±¡
 * @param env ç’°å¢ƒè®Šæ•¸
 * @returns å›æ‡‰å°è±¡
 */
export async function handleChat(request: Request, env: Env): Promise<Response> {
  console.log('=== æ”¶åˆ°èŠå¤©è«‹æ±‚ ===');
  console.log('è«‹æ±‚ URL:', request.url);
  console.log('è«‹æ±‚æ–¹æ³•:', request.method);
  console.log('è«‹æ±‚ä¾†æº:', request.headers.get('Origin'));
  console.log('Worker ç’°å¢ƒè®Šæ•¸æª¢æŸ¥:', {
    hasGroqApiKey: !!env.GROQ_API_KEY,
    apiKeyLength: env.GROQ_API_KEY ? env.GROQ_API_KEY.length : 0,
  });
  
  // æ·»åŠ  CORS æ¨™é ­
  const headers = { ...getCorsHeadersForRequest(request), 'Content-Type': 'application/json' };
  
  try {
    // é©—è­‰è«‹æ±‚æ–¹æ³•
    if (request.method !== 'POST') {
      console.log('âŒ è«‹æ±‚å¤±æ•—: æ–¹æ³•ä¸å…è¨± -', request.method);
      return new Response(JSON.stringify({ 
        success: false, 
        error: { message: 'æ–¹æ³•ä¸å…è¨±' } 
      }), { 
        status: 405, 
        headers 
      });
    }
    
    // è§£æè«‹æ±‚æ•¸æ“š
    const data = await request.json() as ChatCompletionOptions;
    console.log('ğŸ“ è«‹æ±‚å…§å®¹æ‘˜è¦:', {
      messagesCount: data.messages?.length || 0,
      requestedModel: data.model || DEFAULT_MODEL,
      temperature: data.temperature || DEFAULT_TEMPERATURE,
      maxTokens: data.maxTokens || DEFAULT_MAX_TOKENS,
      firstUserMessage: data.messages?.[0]?.content?.substring(0, 50) + '...' || 'ç„¡å…§å®¹'
    });
    
    // æª¢æŸ¥å¿…è¦åƒæ•¸
    if (!data.messages || !Array.isArray(data.messages) || data.messages.length === 0) {
      console.log('âŒ è«‹æ±‚å¤±æ•—: ç¼ºå°‘èŠå¤©è¨Šæ¯');
      return new Response(JSON.stringify({ 
        success: false, 
        error: { message: 'ç¼ºå°‘èŠå¤©è¨Šæ¯' } 
      }), { 
        status: 400, 
        headers 
      });
    }
    
    console.log('ğŸ”„ é–‹å§‹èª¿ç”¨ Groq API...');
    // èª¿ç”¨ Groq API
    const groqResponse = await callGroqApi(data, env);
    
    console.log('âœ… Groq API èª¿ç”¨æˆåŠŸ');
    console.log('å›æ‡‰æ‘˜è¦:', {
      model: groqResponse.model,
      totalTokens: groqResponse.usage?.total_tokens || 0,
      responseTime: new Date().toISOString(), // ä½¿ç”¨ç•¶å‰æ™‚é–“ä»£æ›¿
      firstResponseWords: groqResponse.choices[0]?.message?.content?.substring(0, 50) + '...' || 'ç„¡å…§å®¹'
    });
    
    // è¿”å›æˆåŠŸå›æ‡‰
    return new Response(JSON.stringify({
      success: true,
      data: groqResponse
    }), { 
      status: 200, 
      headers 
    });
    
  } catch (error) {
    console.error('âŒ èŠå¤©è™•ç†éŒ¯èª¤:', error);
    console.error('éŒ¯èª¤è©³æƒ…:', error instanceof Error ? {
      message: error.message,
      stack: error.stack
    } : 'æœªçŸ¥éŒ¯èª¤é¡å‹');
    
    // è¿”å›éŒ¯èª¤å›æ‡‰
    return new Response(JSON.stringify({
      success: false,
      error: {
        message: error instanceof Error ? error.message : 'è™•ç†èŠå¤©è«‹æ±‚æ™‚ç™¼ç”ŸéŒ¯èª¤'
      }
    }), { 
      status: 500, 
      headers 
    });
  }
}

/**
 * èª¿ç”¨ Groq API 
 * @param options èŠå¤©å®Œæˆé¸é …
 * @param env ç’°å¢ƒè®Šæ•¸
 * @returns Groq API å›æ‡‰
 */
async function callGroqApi(
  { messages, model = DEFAULT_MODEL, temperature = DEFAULT_TEMPERATURE, maxTokens = DEFAULT_MAX_TOKENS, image }: ChatCompletionOptions,
  env: Env
): Promise<GroqChatResponse> {
  try {
    const url = 'https://api.groq.com/openai/v1/chat/completions';
    
    // æ ¹æ“šå‰ç«¯é¸æ“‡çš„æ¨¡å‹ ID æ˜ å°„åˆ°å¯¦éš›æ¨¡å‹åç¨±å’Œåƒæ•¸
    let actualModel = DEFAULT_MODEL;
    let actualTemperature = temperature;
    let actualMaxTokens = maxTokens;
    let modelDisplayName = 'é è¨­æ¨¡å‹';
    
    // ä½¿ç”¨æ˜ å°„è¡¨è™•ç†æ¨¡å‹é¸æ“‡
    if (model in MODEL_MAPPING) {
      const modelConfig = MODEL_MAPPING[model as keyof typeof MODEL_MAPPING];
      actualModel = modelConfig.name;
      modelDisplayName = modelConfig.displayName;
      
      // å¦‚æœæ²’æœ‰æ˜ç¢ºå‚³å…¥æº«åº¦å’Œæœ€å¤§ tokensï¼Œå‰‡ä½¿ç”¨å°æ‡‰æ¨¡å‹çš„å»ºè­°å€¼
      if (temperature === DEFAULT_TEMPERATURE) {
        actualTemperature = modelConfig.temperature;
      }
      if (maxTokens === DEFAULT_MAX_TOKENS) {
        actualMaxTokens = modelConfig.maxTokens;
      }
      
      console.log(`ğŸ”„ åˆ‡æ›åˆ°æ¨¡å‹: ${modelDisplayName} (ID: ${model})`);
      console.log(`ğŸ“ æ¨¡å‹åƒæ•¸: æº«åº¦=${actualTemperature}, æœ€å¤§Tokens=${actualMaxTokens}`);
    } else if (model.includes('llama') || model.includes('deepseek') || model.includes('qwen')) {
      // å¦‚æœå‚³å…¥çš„æ˜¯å®Œæ•´æ¨¡å‹åç¨±ï¼Œç›´æ¥ä½¿ç”¨
      actualModel = model;
      modelDisplayName = model;
      console.log(`ğŸ”„ ä½¿ç”¨ç›´æ¥æŒ‡å®šçš„æ¨¡å‹: ${model}`);
    } else {
      console.log(`âš ï¸ æœªçŸ¥æ¨¡å‹ ID: ${model}ï¼Œä½¿ç”¨é è¨­æ¨¡å‹: ${DEFAULT_MODEL}`);
    }
    
    console.log('ğŸ“Š Groq API è«‹æ±‚è©³æƒ…:', {
      modelId: model,
      actualModel: actualModel,
      modelName: modelDisplayName,
      messagesCount: messages.length,
      temperature: actualTemperature,
      maxTokens: actualMaxTokens,
      hasImage: !!image
    });
    
    // æª¢æŸ¥ API é‡‘é‘°
    if (!env.GROQ_API_KEY) {
      console.error('âŒ ç¼ºå°‘ Groq API é‡‘é‘°');
      throw new Error('æœªè¨­å®š Groq API é‡‘é‘°');
    }
    
    // åœ¨è¨Šæ¯é–‹é ­åŠ å…¥ç³»çµ±æç¤ºè©
    const messagesWithSystemPrompt = [SYSTEM_PROMPT, ...messages];
    console.log('ğŸ”„ æ·»åŠ ç³»çµ±æç¤ºè©ï¼Œæœ€çµ‚è¨Šæ¯æ•¸é‡:', messagesWithSystemPrompt.length);
    
    // æº–å‚™è«‹æ±‚é«”
    const requestBody: any = {
      model: actualModel,  // ä½¿ç”¨æ˜ å°„å¾Œçš„æ¨¡å‹åç¨±
      messages: messagesWithSystemPrompt,
      temperature: actualTemperature,
      max_tokens: actualMaxTokens
    };

    // å¦‚æœæ˜¯ maverick æ¨¡å‹ä¸”æœ‰åœ–ç‰‡ï¼Œæ·»åŠ åœ–ç‰‡åˆ°è«‹æ±‚ä¸­
    if (model === 'maverick' && image) {
      console.log('ğŸ–¼ï¸ æª¢æ¸¬åˆ°åœ–ç‰‡ä¸Šå‚³ï¼Œæ·»åŠ åˆ° maverick æ¨¡å‹è«‹æ±‚ä¸­');
      
      // ä¿®æ”¹æœ€å¾Œä¸€æ¢ç”¨æˆ¶è¨Šæ¯ï¼Œæ·»åŠ åœ–ç‰‡
      const lastUserMessageIndex = requestBody.messages.findIndex(
        (msg: ChatMessage) => msg.role === 'user'
      );
      
      if (lastUserMessageIndex !== -1) {
        const lastUserMessage = requestBody.messages[lastUserMessageIndex];
        
        // å°‡æœ€å¾Œä¸€æ¢ç”¨æˆ¶è¨Šæ¯è½‰æ›ç‚ºå¤šæ¨¡æ…‹æ ¼å¼
        requestBody.messages[lastUserMessageIndex] = {
          role: 'user',
          content: [
            { type: 'text', text: lastUserMessage.content },
            { 
              type: 'image_url', 
              image_url: {
                url: image
              }
            }
          ]
        };
        
        console.log('âœ… å·²å°‡åœ–ç‰‡æ·»åŠ åˆ°ç”¨æˆ¶è¨Šæ¯ä¸­');
      } else {
        console.log('âš ï¸ æœªæ‰¾åˆ°ç”¨æˆ¶è¨Šæ¯ï¼Œç„¡æ³•æ·»åŠ åœ–ç‰‡');
      }
    }
    
    // ç™¼é€è«‹æ±‚åˆ° Groq API
    console.log(`ğŸŒ ç™¼é€è«‹æ±‚åˆ° Groq API (æ¨¡å‹: ${modelDisplayName})...`);
    const startTime = Date.now();
    const response = await fetch(url, {
      method: 'POST',
      headers: {
        'Content-Type': 'application/json',
        'Authorization': `Bearer ${env.GROQ_API_KEY}`
      },
      body: JSON.stringify(requestBody)
    });
    const endTime = Date.now();
    console.log(`â±ï¸ Groq API è«‹æ±‚è€—æ™‚: ${endTime - startTime}ms (æ¨¡å‹: ${modelDisplayName})`);
    
    // æª¢æŸ¥å›æ‡‰ç‹€æ…‹
    if (!response.ok) {
      const errorData = await response.json();
      console.error('âŒ Groq API å›æ‡‰éŒ¯èª¤:', {
        status: response.status,
        statusText: response.statusText,
        errorData: errorData
      });
      throw new Error(`Groq API éŒ¯èª¤: ${JSON.stringify(errorData)}`);
    }
    
    // è§£æå›æ‡‰
    const responseData = await response.json() as GroqChatResponse;
    console.log(`âœ… æ¨¡å‹ ${modelDisplayName} å›æ‡‰æˆåŠŸ:`, {
      model: responseData.model,
      usage: responseData.usage,
      responseCharCount: responseData.choices[0]?.message?.content?.length || 0
    });
    
    // è¿”å› Groq API å›æ‡‰
    return responseData;
    
  } catch (error) {
    console.error('âŒ Groq API è«‹æ±‚éŒ¯èª¤:', error);
    console.error('éŒ¯èª¤è©³æƒ…:', error instanceof Error ? {
      name: error.name,
      message: error.message,
      stack: error.stack
    } : 'æœªçŸ¥éŒ¯èª¤é¡å‹');
    throw error;
  }
} 